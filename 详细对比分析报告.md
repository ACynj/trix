# 实验结果详细对比分析报告

## 一、总体统计

### 归纳数据集 (Inductive)
- **总数据集数**: 41个
- **MRR提升**: 20个 (48.8%)
- **MRR下降**: 21个 (51.2%)
- **Hits@10提升**: 22个 (53.7%)
- **Hits@10下降**: 5个 (12.2%)
- **平均MRR变化**: +0.0095
- **平均Hits@10变化**: +0.0043

### 转导数据集 (Transductive)
- **总数据集数**: 13个
- **MRR提升**: 9个 (69.2%)
- **MRR下降**: 4个 (30.8%)
- **Hits@10提升**: 10个 (76.9%)
- **Hits@10下降**: 2个 (15.4%)
- **平均MRR变化**: +0.0146
- **平均Hits@10变化**: +0.0106

## 二、关键发现

### 1. 表现优秀的数据集（MRR提升 > 0.02）

#### 归纳数据集：
- **WN18RRInductive(v3)**: MRR +0.1088 (最大提升！)
- **WN18RRInductive(v2)**: MRR +0.0464
- **WKIngram(50)**: MRR +0.0429
- **WikiTopicsMT4(health)**: MRR +0.0383
- **WikiTopicsMT2(sci)**: MRR +0.0341
- **WikiTopicsMT3(infra)**: MRR +0.0293
- **WKIngram(100)**: MRR +0.0282
- **HM(1k)**: MRR +0.0745
- **HM(3k)**: MRR +0.0576
- **HM(5k)**: MRR +0.0471

#### 转导数据集：
- **Hetionet**: MRR +0.0741
- **YAGO310**: MRR +0.0596
- **DBpedia100k**: MRR +0.0493
- **NELL23k**: MRR +0.0349
- **WDsinger**: MRR +0.0288 (Hits@10 +0.0717，最大H@10提升！)

### 2. 表现较差的数据集（MRR下降 > 0.02）

#### 归纳数据集：
- **ILPC2022(large)**: MRR -0.0402
- **FBIngram(75)**: MRR -0.0279
- **FB15k237Inductive(v1)**: MRR -0.0268
- **FB15k237Inductive(v4)**: MRR -0.0231
- **WikiTopicsMT1(health)**: MRR -0.0248

#### 转导数据集：
- **CoDExLarge**: MRR -0.0424
- **CoDExSmall**: MRR -0.0240
- **NELL995**: MRR -0.0295

### 3. 模式分析

#### 表现好的数据集特征：
1. **小到中等规模**：WN18RR系列、HM系列、WKIngram系列
2. **稀疏/长尾关系**：HM、Metafam
3. **特定领域**：WikiTopics系列（部分）

#### 表现差的数据集特征：
1. **大规模数据集**：ILPC2022(large)、CoDExLarge、FB15k237系列
2. **高关系密度**：FB15k237、FBIngram部分版本
3. **复杂关系结构**：部分WikiTopics子集

## 三、Hits@10 vs MRR 对比

### 重要观察：
- **Hits@10表现普遍更好**：即使MRR下降，Hits@10往往持平或提升
- 说明方法在**top-10召回**上表现稳定，但在**精确排序**上需要改进

### 典型案例：
- **FB15k237Inductive(v1)**: MRR -0.0268，但Hits@10 +0.0097
- **ILPC2022(large)**: MRR -0.0402，但Hits@10 +0.0080
- **FBIngram(75)**: MRR -0.0279，但Hits@10 +0.0052

## 四、改进建议（按优先级）

### 🔴 高优先级（立即执行）

#### 1. 针对大规模数据集降低Beta
**问题数据集**：
- ILPC2022(large): 训练样本202k，MRR下降0.0402
- CoDExLarge: 训练样本551k，MRR下降0.0424
- FB15k237系列: 训练样本27k-136k，MRR下降0.0076-0.0268

**建议**：
```yaml
# 根据训练集大小自动调整beta
训练样本 < 10k:  beta = 1e-3  (当前值)
训练样本 10k-50k: beta = 5e-4
训练样本 50k-200k: beta = 1e-4
训练样本 > 200k:  beta = 5e-5
```

**实施步骤**：
1. 在FB15k237 v1上测试beta=1e-4和5e-4
2. 在ILPC2022(large)上测试beta=1e-4和5e-5
3. 根据结果建立数据集规模→beta映射表

#### 2. 为表现差的数据集创建专门配置
创建以下配置文件：
- `config/run_relation_inductive_mech_fb15k237.yaml` (beta=1e-4)
- `config/run_relation_inductive_mech_ilpc2022.yaml` (beta=5e-4)
- `config/run_relation_transductive_mech_codex.yaml` (beta=1e-4)

### 🟡 中优先级（1周内完成）

#### 3. 分析成功案例，提取可复用模式
**成功案例特征分析**：
- WN18RR系列：所有版本都提升，平均+0.0492
- HM系列（1k/3k/5k）：平均+0.0597
- WKIngram系列：平均+0.0247

**可能原因**：
- 这些数据集的关系结构更适合latent mechanism建模
- 机制编码器能更好地捕获这些数据集的模式

**建议**：
- 分析这些数据集的共同特征（关系数量、实体数量、图密度等）
- 尝试将这些特征作为beta选择的依据

#### 4. 改进机制编码器容量
对于大规模数据集，当前编码器可能容量不足：
- 增加编码器深度（2层→3-4层）
- 增加z_dim（32→64，仅对大数据集）
- 引入残差连接

### 🟢 低优先级（长期优化）

#### 5. 实现自适应Beta策略
根据数据集特征自动选择beta：
```python
def auto_select_beta(dataset_name, num_train, num_relations, graph_density):
    if num_train > 200000:
        return 5e-5
    elif num_train > 50000:
        return 1e-4
    elif num_relations > 1000:
        return 5e-4
    else:
        return 1e-3
```

#### 6. KL Warmup策略
训练初期逐渐增加beta，避免过早约束：
- 前5个epoch: beta线性从0增加到目标值
- 后续epoch: 保持目标beta值

## 五、具体行动计划

### 第一阶段（1-2天）：快速修复
1. ✅ 在FB15k237 v1上测试beta=[1e-4, 5e-4, 1e-3]
2. ✅ 在ILPC2022(large)上测试beta=[5e-5, 1e-4, 5e-4]
3. ✅ 找到最优beta后，更新配置文件

### 第二阶段（3-5天）：系统性优化
1. 为所有表现差的数据集找到最优beta
2. 建立"数据集→beta"映射表
3. 重新跑所有数据集，验证改进效果

### 第三阶段（1-2周）：深度优化
1. 改进机制编码器（增加容量）
2. 实现自适应beta选择
3. 添加KL warmup支持

## 六、预期改进效果

### 短期目标（完成第一阶段后）
- FB15k237系列：MRR恢复到baseline水平（±0.01内）
- ILPC2022系列：MRR恢复到baseline水平
- 整体平均MRR提升：从+0.0095提升到+0.015+

### 中期目标（完成第二阶段后）
- 所有数据集MRR ≥ baseline
- 平均MRR提升：+0.02以上
- 至少80%的数据集有提升

### 长期目标（完成第三阶段后）
- 实现完全自适应的beta选择
- 所有数据集都有提升或至少持平
- 建立通用的超参数选择规则

## 七、关键指标总结

| 指标 | 归纳数据集 | 转导数据集 | 总体 |
|------|-----------|-----------|------|
| 平均MRR变化 | +0.0095 | +0.0146 | +0.0110 |
| MRR提升比例 | 48.8% | 69.2% | 53.7% |
| 平均H@10变化 | +0.0043 | +0.0106 | +0.0062 |
| H@10提升比例 | 81.5% | 76.9% | 80.4% |

**结论**：
- ✅ 方法在转导数据集上表现更好（69.2%提升率）
- ✅ Hits@10表现稳定（80%+提升率）
- ⚠️ 归纳数据集MRR提升率略低（48.8%），需要针对性优化
- ✅ 整体趋势积极，平均都有提升

## 八、下一步行动

1. **立即执行**：在FB15k237 v1和ILPC2022(large)上测试不同beta值
2. **本周完成**：为所有表现差的数据集找到最优beta
3. **持续优化**：分析成功案例，改进编码器，实现自适应策略

