output_dir: /T20030104/ynj/TRIX/output_rel/

dataset:
  class: JointDataset
  graphs: [FB15k237, WN18RR, CoDExMedium]
  root: /kg-datasets/

model:
  class: TRIXLatentMechanismPretrain
  trix:
    feature_dim: 32
    num_layer: 3
    num_mlp_layer: 2
  relation_model:
    class: NBFNet
    input_dim: 32
    hidden_dims: [32, 32]
    message_func: distmult
    aggregate_func: sum
    short_cut: yes
    layer_norm: yes
  entity_model:
    class: IndNBFNet
    input_dim: 32
    hidden_dims: [32, 32]
    message_func: distmult
    aggregate_func: sum
    short_cut: yes
    layer_norm: yes
  mechanism:
    enabled: true
    z_dim: 32
    beta: 1.5e-4          # 更低的beta，让机制z更灵活，最大化WN18RR潜力
    deterministic_eval: true
    score_type: concat_mlp

task:
  name: MultiGraphPretraining
  num_negative: 512
  strict_negative: yes
  adversarial_temperature: 1
  metric: [mr, mrr, hits@1, hits@3, hits@10]

optimizer:
  class: AdamW
  lr: 3.5e-4             # 稍微降低学习率，配合更长训练
  weight_decay: 1.5e-5   # 更强的权重衰减，防止过拟合

train:
  gpus: {{ gpus }}
  batch_size: 32
  num_epoch: 30          # 更长训练，让WN18RR充分收敛
  log_interval: 800
  batch_per_epoch: 1000
  fast_test: 500
  logger: wandb



